---
title: "Jeu de Donjon IA"
description: "Un guide pas √† pas pour construire un jeu d'aventure de donjon aliment√© par l'IA en utilisant le @aws/nx-plugin."
---



import { Aside, Code, FileTree, Steps, Tabs, TabItem } from '@astrojs/starlight/components';
import { Image } from 'astro:assets';
import Drawer from '@components/drawer.astro';
import Link from '@components/link.astro';
import RunGenerator from '@components/run-generator.astro';
import NxCommands from '@components/nx-commands.astro';
import InstallCommand from '@components/install-command.astro';
import dungeonAdventureArchitecturePng from '@assets/dungeon-game-architecture.png'
import dungeonAdventureErPng from '@assets/dungeon-adventure-er.png'
import baselineWebsitePng from '@assets/baseline-website.png'
import baselineGamePng from '@assets/baseline-game.png'
import nxGraphPng from '@assets/nx-graph.png'
import gameSelectPng from '@assets/game-select.png'
import gameConversationPng from '@assets/game-conversation.png'

## Module 3 : Impl√©mentation de l'API Story

<Aside type="caution">
Assurez-vous d'avoir accord√© l'acc√®s au mod√®le **Anthropic Claude 3.5 Sonnet v2** en suivant les √©tapes d√©crites dans [ce guide](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html).
</Aside>

La StoryApi comprend une unique API `generate_story` qui, √©tant donn√© un `Game` et une liste d'`Action` comme contexte, fait progresser une histoire. Cette API sera impl√©ment√©e comme une API de streaming en Python/FastAPI et d√©montrera √©galement comment modifier le code g√©n√©r√© pour l'adapter √† son usage.

### Impl√©mentation de l'API

Pour cr√©er notre API, nous devons d'abord installer quelques d√©pendances suppl√©mentaires :

- `boto3` sera utilis√© pour appeler Amazon Bedrock ;
- `uvicorn` sera utilis√© pour d√©marrer notre API en conjonction avec le [Lambda Web Adapter (LWA)](https://github.com/awslabs/aws-lambda-web-adapter).
- `copyfiles` est une d√©pendance npm n√©cessaire pour supporter la copie multiplateforme de fichiers lors de la mise √† jour de notre t√¢che `bundle`.

Pour installer ces d√©pendances, ex√©cutez les commandes suivantes :

<NxCommands commands={["run dungeon_adventure.story_api:add --args boto3 uvicorn"]} />
<InstallCommand pkg="copyfiles" dev />

Maintenant rempla√ßons le contenu des fichiers suivants dans `packages/story_api/story_api` :

<Tabs>
<TabItem label="main.py">
```python
// packages/story_api/story_api/main.py
import json

from boto3 import client
from fastapi.responses import PlainTextResponse, StreamingResponse
from pydantic import BaseModel

from .init import app, lambda_handler

handler = lambda_handler

bedrock = client('bedrock-runtime')

class Action(BaseModel):
    role: str
    content: str

class StoryRequest(BaseModel):
    genre: str
    playerName: str
    actions: list[Action]

async def bedrock_stream(request: StoryRequest):
    messages = [
        {"role": "user", "content": "Continue or create a new story..."}
    ]

    for action in request.actions:
        messages.append({"role": action.role, "content": action.content})

    response = bedrock.invoke_model_with_response_stream(
        modelId='anthropic.claude-3-sonnet-20240229-v1:0',
        body=json.dumps({
            "system":f"""
            You are running an AI text adventure game in the {request.genre} genre.
            Player: {request.playerName}. Return less than 200 characters of text.
            """,
            "messages": messages,
            "max_tokens": 1000,
            "temperature": 0.7,
            "anthropic_version": "bedrock-2023-05-31"
        })
    )

    stream = response.get('body')
    if stream:
        for event in stream:
            chunk = event.get('chunk')
            if chunk:
                message = json.loads(chunk.get("bytes").decode())
                if message['type'] == "content_block_delta":
                    yield message['delta']['text'] or ""
                elif message['type'] == "message_stop":
                    yield "\n"

@app.post("/story/generate",
          openapi_extra={'x-streaming': True},
          response_class=PlainTextResponse)
def generate_story(request: StoryRequest) -> str:
    return StreamingResponse(bedrock_stream(request), media_type="text/plain")
```
</TabItem>
<TabItem label="init.py">
```python
// packages/story_api/story_api/init.py
import os
import uuid
from collections.abc import Callable

from aws_lambda_powertools import Logger, Metrics, Tracer
from aws_lambda_powertools.metrics import MetricUnit
from fastapi import FastAPI, Request, Response
from fastapi.openapi.utils import get_openapi
from fastapi.responses import JSONResponse
from fastapi.routing import APIRoute
from mangum import Mangum
from pydantic import BaseModel
from starlette.middleware.exceptions import ExceptionMiddleware

os.environ["POWERTOOLS_METRICS_NAMESPACE"] = "StoryApi"
os.environ["POWERTOOLS_SERVICE_NAME"] = "StoryApi"

logger: Logger = Logger()
metrics: Metrics = Metrics()
tracer: Tracer = Tracer()

class InternalServerErrorDetails(BaseModel):
    detail: str

app = FastAPI(
    title="StoryApi",
    responses={
        500: {"model": InternalServerErrorDetails}
    }
)
lambda_handler = Mangum(app)

# Add tracing
lambda_handler.__name__ = "handler"  # tracer requires __name__ to be set
lambda_handler = tracer.capture_lambda_handler(lambda_handler)
# Add logging
lambda_handler = logger.inject_lambda_context(lambda_handler, clear_state=True)
# Add metrics last to properly flush metrics.
lambda_handler = metrics.log_metrics(lambda_handler, capture_cold_start_metric=True)

# Add exception middleware(s)
app.add_middleware(ExceptionMiddleware, handlers=app.exception_handlers)

@app.exception_handler(Exception)
async def unhandled_exception_handler(request, err):
    logger.exception("Unhandled exception")

    metrics.add_metric(name="Failure", unit=MetricUnit.Count, value=1)

    return JSONResponse(status_code=500,
                        content=InternalServerErrorDetails(
                            detail="Internal Server Error").model_dump())

@app.middleware("http")
async def metrics_handler(request: Request, call_next):
    metrics.add_dimension("route", f"{request.method} {request.url.path}")
    metrics.add_metric(name="RequestCount", unit=MetricUnit.Count, value=1)

    response = await call_next(request)

    if response.status_code == 200:
        metrics.add_metric(name="Success", unit=MetricUnit.Count, value=1)

    return response

# Add correlation id middleware
@app.middleware("http")
async def add_correlation_id(request: Request, call_next):
    # Get correlation id from X-Correlation-Id header
    corr_id = request.headers.get("x-correlation-id")
    if not corr_id and "aws.context" in request.scope:
        # If empty, use request id from aws context
        corr_id = request.scope["aws.context"].aws_request_id
    elif not corr_id:
        # If still empty, use uuid
        corr_id = uuid.uuid4().hex

    # Add correlation id to logs
    logger.set_correlation_id(corr_id)

    response = await call_next(request)

    # Return correlation header in response
    response.headers["X-Correlation-Id"] = corr_id
    return response

class LoggerRouteHandler(APIRoute):
    def get_route_handler(self) -> Callable:
        original_route_handler = super().get_route_handler()

        async def route_handler(request: Request) -> Response:
            # Add fastapi context to logs
            ctx = {
                "path": request.url.path,
                "route": self.path,
                "method": request.method,
            }
            logger.append_keys(fastapi=ctx)
            logger.info("Received request")

            return await original_route_handler(request)

        return route_handler

app.router.route_class = LoggerRouteHandler

def custom_openapi():
    if app.openapi_schema:
        return app.openapi_schema
    for route in app.routes:
        if isinstance(route, APIRoute):
            route.operation_id = route.name
    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        openapi_version=app.openapi_version,
        description=app.description,
        routes=app.routes,
    )
    app.openapi_schema = openapi_schema
    return app.openapi_schema

app.openapi = custom_openapi

```

:::note
La modification ci-dessus de `init.py` supprime simplement le middleware CORS pour √©viter les conflits avec la gestion des en-t√™tes CORS propre √† l'URL de fonction Lambda.
:::

</TabItem>
</Tabs>

Analyse du code :

- Nous utilisons le param√®tre `x-streaming` pour indiquer qu'il s'agit d'une API de streaming lors de la g√©n√©ration de notre SDK client. Cela permet de consommer cette API en streaming tout en conservant la s√©curit√© des types !
- Notre API retourne simplement un flux texte comme d√©fini par `media_type="text/plain"` et `response_class=PlainTextResponse`

:::note
√Ä chaque modification de votre FastAPI, vous devrez reconstruire votre projet pour voir les changements refl√©t√©s dans le client g√©n√©r√© de votre site.

Nous allons apporter quelques modifications suppl√©mentaires ci-dessous avant de reconstruire.
:::

### Infrastructure

L'<Link path="get_started/tutorials/dungeon-game/1#game-ui-infrastructure">infrastructure configur√©e pr√©c√©demment</Link> suppose que toutes les APIs utilisent une API Gateway int√©gr√©e avec des fonctions Lambda. Pour notre `story_api`, nous ne souhaitons pas utiliser API Gateway car il ne supporte pas les r√©ponses en streaming. √Ä la place, nous utiliserons une [URL de fonction Lambda configur√©e avec le streaming de r√©ponse](https://docs.aws.amazon.com/lambda/latest/dg/configuration-response-streaming.html).

Pour supporter cela, nous allons d'abord mettre √† jour nos constructs CDK comme suit :

<Tabs>
<TabItem label="story-api.ts">
```ts
// packages/common/constructs/src/app/apis/story-api.ts
import { Duration, Stack, CfnOutput } from 'aws-cdk-lib';
import { IGrantable, Grant } from 'aws-cdk-lib/aws-iam';
import {
  Runtime,
  Code,
  Tracing,
  LayerVersion,
  FunctionUrlAuthType,
  InvokeMode,
  Function,
} from 'aws-cdk-lib/aws-lambda';
import { Construct } from 'constructs';
import url from 'url';
import { RuntimeConfig } from '../../core/runtime-config.js';

export class StoryApi extends Construct {
  public readonly handler: Function;

  constructor(scope: Construct, id: string) {
    super(scope, id);

    this.handler = new Function(this, 'Handler', {
      runtime: Runtime.PYTHON_3_12,
      handler: 'run.sh',
      code: Code.fromAsset(
        url.fileURLToPath(
          new URL(
            '../../../../../../dist/packages/story_api/bundle',
            import.meta.url,
          ),
        ),
      ),
      timeout: Duration.seconds(30),
      tracing: Tracing.ACTIVE,
      environment: {
        AWS_CONNECTION_REUSE_ENABLED: '1',
      },
    });

    const stack = Stack.of(this);
    this.handler.addLayers(
      LayerVersion.fromLayerVersionArn(
        this,
        'LWALayer',
        `arn:aws:lambda:${stack.region}:753240598075:layer:LambdaAdapterLayerX86:24`,
      ),
    );
    this.handler.addEnvironment('PORT', '8000');
    this.handler.addEnvironment('AWS_LWA_INVOKE_MODE', 'response_stream');
    this.handler.addEnvironment('AWS_LAMBDA_EXEC_WRAPPER', '/opt/bootstrap');
    const functionUrl = this.handler.addFunctionUrl({
      authType: FunctionUrlAuthType.AWS_IAM,
      invokeMode: InvokeMode.RESPONSE_STREAM,
      cors: {
        allowedOrigins: ['*'],
        allowedHeaders: [
          'authorization',
          'content-type',
          'x-amz-content-sha256',
          'x-amz-date',
          'x-amz-security-token',
        ],
      },
    });

    new CfnOutput(this, 'StoryApiUrl', { value: functionUrl.url });

    // Enregistre l'URL de l'API dans la configuration runtime pour la d√©couverte client
    RuntimeConfig.ensure(this).config.apis = {
      ...RuntimeConfig.ensure(this).config.apis!,
      StoryApi: functionUrl.url,
    };
  }

  public grantInvokeAccess(grantee: IGrantable) {
    Grant.addToPrincipal({
      grantee,
      actions: ['lambda:InvokeFunctionUrl'],
      resourceArns: [this.handler.functionArn],
      conditions: {
        StringEquals: {
          'lambda:FunctionUrlAuthType': 'AWS_IAM',
        },
      },
    });
  }
}

```
</TabItem>
<TabItem label="application-stack.ts">
```diff lang="typescript"
// packages/infra/src/stacks/application-stack.ts
import {
  GameApi,
  GameUI,
  StoryApi,
  UserIdentity,
} from ':dungeon-adventure/common-constructs';
import * as cdk from 'aws-cdk-lib';
import { Construct } from 'constructs';
import { ElectrodbDynamoTable } from '../constructs/electrodb-table.js';
+import { PolicyStatement, Effect } from 'aws-cdk-lib/aws-iam';

export class ApplicationStack extends cdk.Stack {
  constructor(scope: Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);

    // Le code d√©finissant votre stack se trouve ici
    const userIdentity = new UserIdentity(this, 'UserIdentity');

    const electroDbTable = new ElectrodbDynamoTable(this, 'ElectroDbTable');

    const gameApi = new GameApi(this, 'GameApi', {
      integrations: GameApi.defaultIntegrations(this)
        .withDefaultOptions({
          environment: {
            TABLE_NAME: electroDbTable.tableName,
          },
        })
        .build(),
    });

    // Accorde les acc√®s en lecture/√©criture √† chaque handler selon ses besoins
    electroDbTable.grantReadData(gameApi.integrations['actions.query'].handler);
    electroDbTable.grantReadData(gameApi.integrations['games.query'].handler);
    electroDbTable.grantReadWriteData(
      gameApi.integrations['actions.save'].handler,
    );
    electroDbTable.grantReadWriteData(
      gameApi.integrations['games.save'].handler,
    );

-    const storyApi = new StoryApi(this, 'StoryApi', {
-      integrations: StoryApi.defaultIntegrations(this).build(),
-    });
+    const storyApi = new StoryApi(this, 'StoryApi');
+    storyApi.handler.addToRolePolicy(
+      new PolicyStatement({
+        effect: Effect.ALLOW,
+        actions: ['bedrock:InvokeModelWithResponseStream'],
+        resources: [
+          'arn:aws:bedrock:*::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0',
+        ],
+      }),
+    );

    // accorde √† notre r√¥le authentifi√© l'acc√®s √† invoquer nos APIs
    [storyApi, gameApi].forEach((api) =>
      api.grantInvokeAccess(userIdentity.identityPool.authenticatedRole),
    );

    // S'assure que ceci est instanci√© en dernier pour que le runtime-config.json soit configur√© automatiquement
    new GameUI(this, 'GameUI');
  }
}

```
</TabItem>
</Tabs>

Maintenant mettons √† jour la `story_api` pour supporter le d√©ploiement avec [Lambda Web Adapter](https://github.com/awslabs/aws-lambda-web-adapter).

<Tabs>
<TabItem label="run.sh">
```bash
// packages/story_api/run.sh
#!/bin/bash

PATH=$PATH:$LAMBDA_TASK_ROOT/bin \
    PYTHONPATH=$PYTHONPATH:/opt/python:$LAMBDA_RUNTIME_DIR \
    exec python -m uvicorn --port=$PORT story_api.main:app
```
</TabItem>
<TabItem label="project.json">
```diff lang="json"
// packages/story_api/project.json
{
  "name": "dungeon_adventure.story_api",
  "$schema": "../../node_modules/nx/schemas/project-schema.json",
  "projectType": "application",
  "sourceRoot": "packages/story_api/story_api",
  "targets": {
    ...
    "bundle": {
      "cache": true,
      "executor": "nx:run-commands",
      "outputs": ["{workspaceRoot}/dist/packages/story_api/bundle"],
      "options": {
        "commands": [
          "uv export --frozen --no-dev --no-editable --project story_api -o dist/packages/story_api/bundle/requirements.txt",
          "uv pip install -n --no-installer-metadata --no-compile-bytecode --python-platform x86_64-manylinux2014 --python `uv python pin` --target dist/packages/story_api/bundle -r dist/packages/story_api/bundle/requirements.txt",
+          "copyfiles -f packages/story_api/run.sh dist/packages/story_api/bundle"
        ],
        "parallel": false
      },
      "dependsOn": ["compile"]
    },
    ...
  }
}
```
</TabItem>
</Tabs>

### D√©ploiement et tests

D'abord, compilons le codebase :

<NxCommands commands={['run-many --target build --all']} />

<Aside type="tip">
Si vous rencontrez des erreurs de lint, vous pouvez ex√©cuter la commande suivante pour les corriger automatiquement :

<NxCommands commands={['run-many --target lint --configuration=fix --all']} />
</Aside>

Votre application peut maintenant √™tre d√©ploy√©e avec la commande suivante :

<NxCommands commands={['run @dungeon-adventure/infra:deploy dungeon-adventure-infra-sandbox']} />

Ce d√©ploiement prendra environ 2 minutes.

<Drawer title="Commande de d√©ploiement" trigger="Vous pouvez aussi d√©ployer toutes les stacks en une fois. Cliquez ici pour plus de d√©tails.">

Vous pouvez √©galement d√©ployer toutes les stacks de l'application CDK avec :

<NxCommands commands={['run @dungeon-adventure/infra:deploy --all']} />

Ceci n'est **pas recommand√©** car vous pourriez vouloir s√©parer vos √©tapes de d√©ploiement en diff√©rentes stacks `ex: infra-prod`. Dans ce cas, le flag `--all` tentera de d√©ployer toutes les stacks, ce qui peut entra√Æner des d√©ploiements non d√©sir√©s !

</Drawer>

Une fois le d√©ploiement termin√©, vous devriez voir des sorties similaires √† ceci _(certaines valeurs ont √©t√© masqu√©es)_ :

```bash
dungeon-adventure-infra-sandbox
dungeon-adventure-infra-sandbox: deploying... [2/2]

 ‚úÖ  dungeon-adventure-infra-sandbox

‚ú®  Dur√©e du d√©ploiement : 354s

Outputs:
dungeon-adventure-infra-sandbox.ElectroDbTableTableNameXXX = dungeon-adventure-infra-sandbox-ElectroDbTableXXX-YYY
dungeon-adventure-infra-sandbox.GameApiEndpointXXX = https://xxx.execute-api.region.amazonaws.com/prod/
dungeon-adventure-infra-sandbox.GameUIDistributionDomainNameXXX = xxx.cloudfront.net
dungeon-adventure-infra-sandbox.StoryApiStoryApiUrlXXX = https://xxx.lambda-url.ap-southeast-2.on.aws/
dungeon-adventure-infra-sandbox.UserIdentityUserIdentityIdentityPoolIdXXX = region:xxx
dungeon-adventure-infra-sandbox.UserIdentityUserIdentityUserPoolIdXXX = region_xxx
```

Nous pouvons tester notre API en :
<ul>
<li>D√©marrant une instance locale du serveur FastApi et en invoquant les API avec `curl`</li>
<li>
<Drawer title="curl avec Sigv4 activ√©" trigger="Appeler l'API d√©ploy√©e directement avec curl sigv4">
Vous pouvez soit ajouter ce script √† votre fichier `.bashrc` (et le `sourcer`), soit simplement coller ce qui suit dans le terminal o√π vous ex√©cuterez la commande.
```bash
// ~/.bashrc
acurl () {
    REGION=$1
    SERVICE=$2
    shift; shift;
    curl --aws-sigv4 "aws:amz:$REGION:$SERVICE" --user "$(aws configure get aws_access_key_id):$(aws configure get aws_secret_access_key)" -H "X-Amz-Security-Token: $(aws configure get aws_session_token)" "$@"
}
```

Exemples d'utilisation de `acurl` :

###### API Gateway
```bash
acurl ap-southeast-2 execute-api -X GET https://xxx
```

###### URL de fonction Lambda en streaming
```bash
acurl ap-southeast-2 lambda -N -X POST https://xxx
```
</Drawer>
</li>
</ul>

<Tabs>
  <TabItem label="Local">
  D√©marrez votre serveur FastAPI local avec :
    <NxCommands commands={["run dungeon_adventure.story_api:serve"]} />

    Une fois le serveur d√©marr√©, appelez-le avec :

    ```bash
    curl -N -X POST http://127.0.0.1:8000/story/generate \
      -d '{"genre":"superhero", "actions":[], "playerName":"UnnamedHero"}' \
      -H "Content-Type: application/json"
    ```
  </TabItem>
  <TabItem label="D√©ploy√©">
```bash "https://xxx.lambda-url.ap-southeast-2.on.aws/" "ap-southeast-2"
acurl ap-southeast-2 lambda -N -X POST \
  https://xxx.lambda-url.ap-southeast-2.on.aws/story/generate \
  -d '{"genre":"superhero", "actions":[], "playerName":"UnnamedHero"}' \
  -H "Content-Type: application/json"
```
    <Aside type="caution">
    Utilisez la valeur de sortie `dungeon-adventure-infra-sandbox.StoryApiStoryApiUrlXXX` du d√©ploiement CDK pour remplacer l'URL et d√©finir la r√©gion appropri√©e.
    </Aside>
  </TabItem>
</Tabs>

Si la commande r√©ussit, vous devriez voir une r√©ponse en streaming similaire √† :

```
UnnamedHero se tenait droit, sa cape flottant au vent....
```

F√©licitations. Vous avez construit et d√©ploy√© votre premi√®re API avec FastAPI ! üéâüéâüéâ